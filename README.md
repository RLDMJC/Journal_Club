# MindRL Hub (强化学习讨论分享社群）

- 组委会成员(姓氏拼音顺序）<br>|| Committee members (alphabetical order)：<br>
  [Zeming Fang 方泽鸣 (SJTU)](https://github.com/fangzefunny), <br>
  [Huaiyu Liu 刘怀瑜 (UCL)](https://iris.ucl.ac.uk/iris/browse/profile?upi=YLIUW71), <br>
  [Yanan Liu 刘亚男 (McGill University)](https://github.com/lynn0503),  
  [Hanbo Xie 谢涵博 (University of Arizona)](https://github.com/xhb120633)

- 微信群：RL 专题分享讨论群 <br>|| WeChat Group: RL 专题分享讨论群

- 微信公众号： MindRL Hub <br>|| WeChat Official Account: MindRL Hub

- 会议地址：Zoom 或腾讯会议， 请关注微信公众号，以公众号上每次活动实际通知为准。<br>
  || Web-based meeting: Zoom or Tencent Meeting, please see the notifications on our Github (https://rldmjc.github.io/)

- 官方网站：https://rldmjc.github.io/ <br>
  || Our Github: https://rldmjc.github.io/

- 主旨：我们联合创立本社群，希望能够为强化学习相关领域的各个层级的研究者提供交流、互助、合作的平台。我们希望和来自心理学、神经科学、人工智能以及其他相关专业如管理学、数学、经济学等交叉领域的同行一起构建更丰富、更有包容性的平台。<br>
  || Goal(s): We co-founded this MindRL Hub Community. This community dedicates to connecting Reinforcement Learning (RL) scholars to exchange their latest research, tools, hands-on tutorials (e.g., Stan, R, MATLAB, Python), etc. In addition, we also hope to foster discussion and collaboration between those involved in RL (e.g., Psychology, Cognitive Neuroscience, AI, Economics, etc.).

- 联系方式: 如果想加入社群、加入 Committee 或参加某次活动，欢迎联系组委会成员。微信：Psych509. [也可邮件联系。](mailto:rldmjc2023@gmail.com) <br> 
|| Contact us: If you wish to join our community, or become a part of the committee, or participant in a specific web-based meeting; please feel free to contact our committee members via either the WeChat (Psych509 or UchihaTed) or e-mail (rldmjc2023@gmail.com), thanks.

![MindRL Hub](https://github.com/RLDMJC/Journal_Club/blob/main/RL_pic.jpg)


## MindRL Hub Past Talks

| 期号<br> (Issue) | 题目<br>(Title)                                                                                       | 报告人<br> (Speaker)                                                                          | 类型<br> (Category)                    | 时间<br> (Date in Beijing Time)                      | 回放<br> (Past talk videos)                                                                                                                    | 语言<br> (Language) | 参考文献<br> (References)
| ------- | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ----------------------- | ------------------------- | ----------------------------------------------------------------------------------------------------------------------- | ---------- | --------- | 
| 1    | Neural network modeling reveals diverse human exploration behaviors via state space analysis | [Huadong Xiong 熊华东 (University of Arizona )](https://sakimarquis.github.io/) | Research Recap 原创研究 | 2023/08/09 14：00 (GMT+8) | [回放](https://www.bilibili.com/video/BV1au4y1R7kh/?spm_id_from=333.999.0.0&vd_source=e9626f9767e6e22ece9d765f34ba01c5) | Chinese
| 2    | 分层贝叶斯强化学习模型的实操示例<br> (Crash tutorials on fitting hierarchical Bayesian reinforcement learning models) | Shen Xu 徐深(Peking University)  | Tutorial Talk 教程实例 | 2023/08/26 21：00 (GMT+8) | [回放](https://www.bilibili.com/video/BV1qm4y1u7JU/?spm_id_from=333.999.0.0&vd_source=1a260a61416c0a766c7c16e727b2f404)| Chinese | [Ten simple rules for the computational modeling of behavioral data](https://elifesciences.org/articles/49547) <br> ; [Neural knowledge assembly in humans and neural networks](https://pubmed.ncbi.nlm.nih.gov/36898375/)<br>; [Cortical substrates for exploratory decisions in humans](https://www.nature.com/articles/nature04766)
| 3    | 工作记忆指导了基于模型的决策中的动作估值<br> (Working memory guides action valuation in model-based inference) | Zhaoyu Zuo 左肇煜 (University of Science and Technology of China)   | Research Recap 原创研究  | 2023/09/09 21:00 (GMT+8) | [回放](https://www.bilibili.com/video/BV1Sj411C77e/?vd_source=e9626f9767e6e22ece9d765f34ba01c5)| Chinese | [How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis](https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1460-9568.2011.07980.x?casa_token=H4JHN0_GQvwAAAAA:U8kymkc8RpFKa3ufOjqr7OWlG5JrElGiq__-837hCod2BY2_Cnnp9K-QJ20W4d2Bar9fo4FWOXBEeaRb) <br> ; [Model-based influences on humans' choices and striatal prediction errors](https://www.cell.com/fulltext/S0896-6273(11)00125-5)<br>; [Beyond dichotomies in reinforcement learning](https://www.nature.com/articles/s41583-020-0355-6)
                  
## MindRL Hub Upcoming Talks

| 题目<br> (Title)                                                            | 报告人<br> (Speaker)                                                                              | 类型<br> (Category)                    | 时间<br> (Date in Beijing Time)                      | 语言<br> (Language) | 摘要<br> (Abstract) | 会议<br> (Meeting link)
| --------------------------------------------------------------- | ----------------------------------------------------------------------------------- | ----------------------- | ------------------------- | ---------| ------- | ------ |
| Reinforcement learning biases that makes us smart                                                             | [Stefano Palminteri (INSERM)](https://sites.google.com/site/stefanopalminteri/home) | Research Recap 原创研究 | 2023/09/15 17:00(GMT+8) | English |  In the present talk I will review research performed by my and other laboratories that highlight the existence of reinforcement leaning biases. I will first start by briefly introducing the reinforcement learning framework and propose a taxonomy of biases within the framework itself. Then I will review direct empirical evidence supporting the existence of two learning biases: positivity bias and value-normalization at both the behavioral, neural and clinical level. Finally, I will present unpublished results of simulation studies that try to answer the question: what are these reinforcement learning biases good for?  | Zoom Meeting ID: 966 7243 4326 Passcode: 733623|
| Trait somatic anxiety is associated with reduced directed exploration and underestimation of uncertainty | [Haoxue Fan (Harvard University)](https://haoxue-fan.github.io/) | Research Recap 原创研究 | 2023/09/22 21:30(GMT+8) | English |
| TBD                                                             | [Mark Ho (Stevens Institute)](https://codec-lab.github.io/)                         | Research Recap 原创研究 | 2023/10/04 21：00 (GMT+8) | English|
| TBD                                                             | [Matt Nassar (Brown University)](https://sites.brown.edu/mattlab/)                  | Research Recap 原创研究 | 2023/10/12 21:00 (GMT+8)  | English|
| TBD                                                             | [Seongmin Park (UC Davis)](https://argmaxv.github.io/)                              | Research Recap 原创研究 | 2023/10/20 14:00 (GMT+8)  | English |
| TBD                                                             | 黄泰诚 (Tsinghua University)                                                        | Journal Jam 文献分享    | 2023/10/23 TBD (GMT+8)    | Chinese
| TBD                                                             | [Charley Wu (University of Tübingen)](https://charleywu.github.io/)                 | Research Recap 原创研究 | 2023/11/08 16:00 (GMT+8)  | English
| RLDDM                                                           | [Miqing Guo 郭鸣谦 (Radboud University)](https://www.ru.nl/en/people/guo-m)         |Tutorial Talk 教程实例   | 2023/11/18 21：00 (GMT+8)  | Chinese
| TBD                                                             | [Weiji Ma 马伟基 (New York University)](http://www.cns.nyu.edu/malab/index.html)     |Research Recap 原创研究 | 2023/12/01 21：30 (GMT+8)  | English
| Compositionality (Exact title TBD)                              | [Michael J Frank (Brown University)](http://ski.clps.brown.edu/)                      |Research Recap 原创研究 | 2023/12/14 21：00 (GMT+8)  | English
